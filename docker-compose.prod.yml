# ==========================================
# Docker Compose - Production Environment
# ==========================================
# Usage: docker-compose -f docker-compose.prod.yml up -d
#
# Prerequisites:
# 1. Copy .env.production.example to .env and fill in values
# 2. Configure reverse proxy (nginx/traefik) for SSL
# 3. Run: docker-compose -f docker-compose.prod.yml up -d

services:
  # ----------------------------------------
  # Database Migration (runs once then exits)
  # ----------------------------------------
  migrate:
    build:
      context: ./backend
      target: production
    environment:
      - DATABASE_URL=postgres://${DB_USER:-droitguineen}:${DB_PASSWORD:?DB_PASSWORD required}@postgres:5432/${DB_NAME:-droitdatabase}
    depends_on:
      postgres:
        condition: service_healthy
    command: ["npx", "prisma", "db", "push", "--skip-generate", "--accept-data-loss"]
    restart: "no"

  # ----------------------------------------
  # Frontend (Next.js)
  # ----------------------------------------
  frontend:
    build:
      context: ./frontend
      target: production
      args:
        NEXT_PUBLIC_API_URL: ${NEXT_PUBLIC_API_URL:?NEXT_PUBLIC_API_URL required (e.g. https://api.example.com)}
        NEXT_PUBLIC_GOOGLE_CLIENT_ID: ${NEXT_PUBLIC_GOOGLE_CLIENT_ID:-}
    ports:
      - "${FRONTEND_PORT:-3000}:3000"
    environment:
      - NODE_ENV=production
      # Internal URL for server-side rendering (Docker DNS)
      - INTERNAL_API_URL=http://backend:4000
    depends_on:
      backend:
        condition: service_healthy
      migrate:
        condition: service_completed_successfully
    deploy:
      replicas: ${FRONTEND_REPLICAS:-1}
      resources:
        limits:
          cpus: '1'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    restart: always
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3000"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s

  # ----------------------------------------
  # Backend (Express.js)
  # ----------------------------------------
  backend:
    build:
      context: ./backend
      target: production
    ports:
      - "${BACKEND_PORT:-4000}:4000"
    environment:
      - NODE_ENV=production
      - PORT=4000
      - DATABASE_URL=postgres://${DB_USER:-droitguineen}:${DB_PASSWORD}@postgres:5432/${DB_NAME:-droitdatabase}
      - SEARCH_URL=http://meili:7700
      - MEILI_MASTER_KEY=${MEILI_MASTER_KEY}
      - JWT_SECRET=${JWT_SECRET:?JWT_SECRET required}
      - CORS_ORIGIN=${CORS_ORIGIN:?CORS_ORIGIN required (e.g. https://example.com)}
      - GOOGLE_CLIENT_ID=${GOOGLE_CLIENT_ID:-}
      - GOOGLE_APPLICATION_CREDENTIALS=/app/credentials/google-vision.json
    depends_on:
      postgres:
        condition: service_healthy
      meili:
        condition: service_healthy
    volumes:
      - backend-uploads:/app/uploads
      - ./credentials:/app/credentials:ro
    deploy:
      replicas: ${BACKEND_REPLICAS:-1}
      resources:
        limits:
          cpus: '2'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:4000/health"]
      interval: 15s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: always
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ----------------------------------------
  # PostgreSQL Database
  # ----------------------------------------
  postgres:
    image: postgres:16-alpine
    environment:
      POSTGRES_USER: ${DB_USER:-droitguineen}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_DB: ${DB_NAME:-droitdatabase}
      PGDATA: /var/lib/postgresql/data/pgdata
    volumes:
      - postgres-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER:-droitguineen} -d ${DB_NAME:-droitdatabase}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M
    restart: always
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ----------------------------------------
  # Meilisearch (Full-text search)
  # ----------------------------------------
  meili:
    image: getmeili/meilisearch:v1.6
    environment:
      MEILI_NO_ANALYTICS: "true"
      MEILI_ENV: production
      MEILI_MASTER_KEY: ${MEILI_MASTER_KEY}
      MEILI_DB_PATH: /meili_data/data.ms
      MEILI_DUMP_DIR: /meili_data/dumps
      MEILI_SNAPSHOT_DIR: /meili_data/snapshots
    volumes:
      - meili-data:/meili_data
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:7700/health"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 256M
    restart: always
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ----------------------------------------
  # Nginx Reverse Proxy (optional)
  # ----------------------------------------
  nginx:
    image: nginx:alpine
    profiles:
      - proxy
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
    depends_on:
      - frontend
      - backend
    restart: always

  # ----------------------------------------
  # Backup Service (optional)
  # ----------------------------------------
  backup:
    image: postgres:16-alpine
    profiles:
      - backup
    environment:
      PGPASSWORD: ${DB_PASSWORD}
    volumes:
      - ./backups:/backups
      - postgres-data:/var/lib/postgresql/data:ro
    entrypoint: |
      /bin/sh -c '
        pg_dump -h postgres -U ${DB_USER:-droitguineen} -d ${DB_NAME:-droitdatabase} -F c > /backups/backup_$$(date +%Y%m%d_%H%M%S).dump
      '
    depends_on:
      postgres:
        condition: service_healthy

# ----------------------------------------
# Volumes
# ----------------------------------------
volumes:
  postgres-data:
    driver: local
  meili-data:
    driver: local
  backend-uploads:
    driver: local

# ----------------------------------------
# Networks
# ----------------------------------------
networks:
  default:
    name: droitguineen-prod-network
